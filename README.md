# EduFact  
### Generative AI Hallucination Checker & Truth Scoring Prototype

EduFact is a **Generative AI prototype** designed to **evaluate the factual accuracy of AI-generated content** and assign a **truth/accuracy score**â€”without modifying or rewriting the original output.

The project focuses on **responsible AI use**, **academic integrity**, and **decision support**, with applications in **education, analytics, and supply chain management**.

---
## ğŸ”— Try the App (Live Prototype)

You can try the **EduFact prototype** here:

ğŸ‘‰ **Live Demo:** https://opal.google/?flow=drive:/1v_4ES9EDF0-D5nrJc34w1BEkAP4kd4tw&shared&mode=app

This interactive demo allows users to:
- Paste **AI-generated content**
- Receive a **truth / accuracy score**
- Identify **potential hallucinations or unverifiable claims**
- Evaluate reliability **without altering the original text**

> âš ï¸ Note: This is a **prototype for academic and experimental use**.  
> Results should be interpreted with **human judgment**.

## ğŸš€ Project Motivation

Large Language Models (LLMs) can generate fluent responses that may still contain **hallucinations**â€”confident but incorrect claims.

EduFact was created to address a key question:

> *How can users trust AI-generated content without blindly accepting it?*

EduFact helps users **assess reliability**, not edit contentâ€”making it suitable for **academic, analytical, and professional settings**.

---

## ğŸ§  What EduFact Does

- Accepts **AI-generated text** as input  
- **Evaluates factual claims** using structured validation prompts  
- Assigns an **accuracy / truth score**  
- Flags **potential hallucinations or unverifiable statements**  
- Preserves the **original AI response** (no rewriting or correction)

âœ… Focuses on **evaluation**, not generation  
âœ… Supports **responsible and ethical GenAI usage**

---

## ğŸ› ï¸ Current Status

- ğŸ”§ **Prototype stage**
- ğŸ“Š Actively conducting **market research and use-case validation**
- ğŸ§ª Tested on educational, analytical, and supply-chain-related content
- âŒ Not a registered company or commercial product

---

## ğŸ“Œ Core Features

- **Hallucination Detection** â€“ Identifies claims that may lack factual grounding  
- **Truth / Accuracy Scoring** â€“ Quantifies reliability instead of binary results  
- **Explainability-focused prompts** â€“ Encourages transparent reasoning  
- **Domain-agnostic design** â€“ Applicable across education, supply chain, and analytics  
- **Academic Integrity Friendly** â€“ Designed for ethical AI use in learning environments  

---

## ğŸ“¦ Example Use Cases

### ğŸ“ Education
- Students validating AI-generated explanations  
- Teaching Assistants reviewing AI-assisted submissions  

### ğŸ“¦ Supply Chain Analytics
- Verifying AI insights on inventory, forecasting, logistics, and disruptions  

### ğŸ§  Decision Support
- Evaluating AI summaries before academic or managerial use  

### ğŸ“š Research & Writing
- Checking factual reliability without altering author intent  

---

## ğŸ§© How It Works (High-Level)

1. User provides **AI-generated content**
2. EduFact breaks content into **verifiable claims**
3. Claims are assessed using **structured validation prompts**
4. Each claim is categorized as:
   - Likely correct  
   - Uncertain  
   - Potential hallucination
5. An **overall truth/accuracy score** is produced

> âš ï¸ EduFact does **not** correct contentâ€”it only evaluates reliability.

---

## ğŸ” Responsible AI Principles

EduFact is built with the following principles:

- Transparency over blind automation  
- Human judgment remains central  
- No content manipulation or rewriting  
- Awareness of model bias and limitations  

---

## ğŸ§‘â€ğŸ’» Tech & Skills Demonstrated

- Prompt engineering & validation workflows  
- Generative AI evaluation logic  
- Ethical AI & hallucination awareness  
- Analytical thinking & system design  
- Application of AI in **education and supply chain analytics**

---

## ğŸ›£ï¸ Future Roadmap

- Domain-specific scoring (e.g., supply chain, finance, education)
- Confidence-level explanations
- UI dashboard for score visualization
- Comparative evaluation across multiple LLMs
- Integration with academic workflows

---

## ğŸ‘©â€ğŸ“ Author

**Harshitha Tankasala**  
M.S. Information Systems (GPA: 4.0)  
Stevens Institute of Technology  

Interests:  
Supply Chain Analytics â€¢ Generative AI â€¢ Responsible AI â€¢ Educational Technology â€¢ Storytelling for Learning  

ğŸ”— LinkedIn: https://www.linkedin.com/in/harshitha-tankasala-6583b4360/

---

## ğŸ“œ Disclaimer

EduFact is an **academic and exploratory prototype** intended for **learning, experimentation, and responsible AI research only**.
